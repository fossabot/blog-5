<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Moos3</title>
    <link>http://blog.guthnur.net/</link>
    <description>Recent content on Moos3</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>All rights reserved - 2015</copyright>
    <lastBuildDate>Sat, 12 Mar 2016 19:49:29 -0500</lastBuildDate>
    <atom:link href="http://blog.guthnur.net/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>back to good engineering</title>
      <link>http://blog.guthnur.net/good-engineer/</link>
      <pubDate>Sat, 12 Mar 2016 19:49:29 -0500</pubDate>
      
      <guid>http://blog.guthnur.net/good-engineer/</guid>
      <description>

&lt;h3 id=&#34;new-employment:bbc45e9cff3753a827d260aaadb41218&#34;&gt;New Employment&lt;/h3&gt;

&lt;p&gt;To begin lets talk about my new employment. I&amp;rsquo;m working for a startup in St Paul. We are doing some really cool stuff with chef and vagrant on my team to manage
all of our infrastructure as we migrate from &lt;a href=&#34;https://www.linode.com&#34;&gt;linode&lt;/a&gt; to &lt;a href=&#34;https://aws.amazon.com&#34;&gt;Amazon AWS&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;good-engineering:bbc45e9cff3753a827d260aaadb41218&#34;&gt;Good Engineering&lt;/h3&gt;

&lt;p&gt;So any company that is starting up these dates are all about the microservices. Piece of advice don&amp;rsquo;t do microservices from the get go. Focus on just getting the application near prefect first then you can do a refactor break it down. Design your front seperate from your backend. So your main application should just be a api and then give that information to the designers and js developers. This is extremely important if you plan on doing a mobile application at somepoint. This will keep the functionality the same between the web ui and the mobile ui.&lt;/p&gt;

&lt;h3 id=&#34;automation:bbc45e9cff3753a827d260aaadb41218&#34;&gt;Automation&lt;/h3&gt;

&lt;p&gt;When it comes your infrastucture automate everything from the begining. This helps scale but make sure that you write in such away that you not locked into a vendor. You should make the vendor pieces just be part of the abstract layer. This will help you launch your infra in aws, digitalocean or any other place. This will also help you create mockup environments for your developers to have mini labs on their local machines.&lt;/p&gt;

&lt;p&gt;Heres to a good future and automating the world!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>kubernetes installation on ubuntu</title>
      <link>http://blog.guthnur.net/kubernetes-ubuntu-installation/</link>
      <pubDate>Tue, 22 Dec 2015 11:32:51 -0800</pubDate>
      
      <guid>http://blog.guthnur.net/kubernetes-ubuntu-installation/</guid>
      <description>

&lt;p&gt;In this article I will show you how to setup kubernetes on ubuntu 14.04 or newer. I recently had to do this for a project.
Below are the steps to complete this with a example pod.&lt;/p&gt;

&lt;h3 id=&#34;steps:2b6cafb974c1a6e3cbf518b2dbee12bf&#34;&gt;steps&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Become Root&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo su -
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Lets get the pre-requisite software packages installed&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get update
apt-get install ssh
apt-get install docker.io
apt-get install curl
apt-get install git
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Password-less ssh login setup, accept all the default parameters in the prompt of the below command (required for Kubernetes installation)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
e1:c9:a5:dd:80:ee:cd:f0:c8:11:6c:a5:d4:ba:ff:cc root@vkohli-Latitude-E7440
The key&#39;s randomart image is:
+--[ RSA 2048]----+
|          ...    |
|         + o.    |
|        o B.     |
|       + B..+    |
|        S o..    |
|       . *..     |
|        . *.     |
|         .  .o   |
|             .E  |
+-----------------+
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Copy the ssh id_rsa key locally&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh-copy-id -i /root/.ssh/id_rsa.pub 127.0.0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In case this fails you can do it by hand. By doing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat /root/.ssh/id_rsa.pub &amp;gt;&amp;gt; /root/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Validate the password-less ssh-login&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ssh root@127.0.0.1
root@vkohli-virtual-machine:~$ exit
logout
Connection to 127.0.0.1 closed
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Get the Kubernetes release bundle from the official github repository&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ wget https://github.com/GoogleCloudPlatform/kubernetes/releases/download/v1.0.1/kubernetes.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Untar the Kubernetes bundle in the same directory&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tar -xvf kubernetes.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We will build the binaries of Kubernetes code specifically for ubuntu cluster&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd kubernetes/cluster/ubuntu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execute the following shell script&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;$ ./build.sh
Download flannel release ...
Flannel version is 0.4.0
% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                Dload  Upload   Total   Spent    Left  Speed
100   411    0   411    0     0    252      0 --:--:--  0:00:01 --:--:--   252
100 2393k  100 2393k    0     0   204k      0  0:00:11  0:00:11 --:--:--  388k
Download etcd release ...
% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   410    0   410    0     0    272      0 --:--:--  0:00:01 --:--:--   272
100 3713k  100 3713k    0     0   286k      0  0:00:12  0:00:12 --:--:--  496k
Download kubernetes release ...
% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                Dload  Upload   Total   Spent    Left  Speed
100   396    0   396    0     0    279      0 --:--:--  0:00:01 --:--:--   279
100 97.8M  100 97.8M    0     0   715k      0  0:02:20  0:02:20 --:--:--  501k
~/kubernetes/cluster/ubuntu/kubernetes/server ~/kubernetes/cluster/ubuntu
~/kubernetes/cluster/ubuntu
Done! All your commands locate in ./binaries dir
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This shell script will download and build the latest version of K8s, etcd and flannel binaries which can be found at following location;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cd binaries
$ ls
kubectl  master  minion
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;kubectl binary controls the Kubernetes cluster manager and the folder master &amp;amp; minion contains the binaries built for the purpose of configuring K8s master and node respectively.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Configure the cluster information by editing only the following parameters of the file &lt;code&gt;cluster/ubuntu/config-default.sh&lt;/code&gt; in the editor of your choice.
&lt;code&gt;
$ cd
$ vi kubernetes/cluster/ubuntu/config-default.sh
export nodes=&amp;quot;root@127.0.0.1&amp;quot;
export roles=&amp;quot;ai&amp;quot;
export NUM_MINIONS=${NUM_MINIONS:-1}
&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Only update the above mentioned information in the file, rest of the configuration will remain as it is. The first variable nodes defines all the cluster nodes, in our case same machine will be configured as master and node so it contains only one entry.The role below “ai” specifies that same machine will act as master, “a” stands for master and “i” stands for node.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Now, we will be starting the cluster with the following command;
```
$ cd kubernetes/cluster
$ KUBERNETES_PROVIDER=ubuntu ./kube-up.sh
Starting cluster using provider: ubuntu
&amp;hellip; calling verify-prereqs
&amp;hellip; calling kube-up
FLANNEL_NET
172.16.0.0/16
Deploying master and minion on machine 127.0.0.1&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;config-default.sh                                                                                100% 2904     2.8KB/s   00:00
util.sh                                                                                          100%   13KB  13.4KB/s   00:00
flanneld.conf                                                                                    100%  569     0.6KB/s   00:00
kube-controller-manager.conf                                                                     100%  746     0.7KB/s   00:00
kube-apiserver.conf                                                                              100%  676     0.7KB/s   00:00
etcd.conf                                                                                        100%  576     0.6KB/s   00:00
kube-scheduler.conf                                                                              100%  676     0.7KB/s   00:00
kube-apiserver                                                                                   100% 2358     2.3KB/s   00:00
kube-controller-manager                                                                          100% 2672     2.6KB/s   00:00
etcd                                                                                             100% 2073     2.0KB/s   00:00
flanneld                                                                                         100% 2159     2.1KB/s   00:00
kube-scheduler                                                                                   100% 2360     2.3KB/s   00:00
reconfDocker.sh                                                                                  100% 1493     1.5KB/s   00:00
kube-proxy.conf                                                                                  100%  648     0.6KB/s   00:00
flanneld.conf                                                                                    100%  569     0.6KB/s   00:00
kubelet.conf                                                                                     100%  634     0.6KB/s   00:00
etcd.conf                                                                                        100%  576     0.6KB/s   00:00
kube-proxy                                                                                       100% 2230     2.2KB/s   00:00
etcd                                                                                             100% 2073     2.0KB/s   00:00
flanneld                                                                                         100% 2159     2.1KB/s   00:00
kubelet                                                                                          100% 2162     2.1KB/s   00:00
kube-apiserver                                                                                   100%   34MB  33.7MB/s   00:00
kube-controller-manager                                                                          100%   26MB  26.2MB/s   00:00
etcdctl                                                                                          100% 6041KB   5.9MB/s   00:00
etcd                                                                                             100% 6494KB   6.3MB/s   00:00
flanneld                                                                                         100% 8695KB   8.5MB/s   00:00
kube-scheduler                                                                                   100%   17MB  17.0MB/s   00:00
kube-proxy                                                                                       100%   17MB  16.8MB/s   00:00
etcdctl                                                                                          100% 6041KB   5.9MB/s   00:00
etcd                                                                                             100% 6494KB   6.3MB/s   00:00
flanneld                                                                                         100% 8695KB   8.5MB/s   00:00
kubelet                                                                                          100%   33MB  33.2MB/s   00:01
[sudo] password to copy files and start node:
etcd start/running, process 1125
Connection to 127.0.0.1 closed.
Validating master
Validating root@127.0.0.1&lt;/p&gt;

&lt;p&gt;Kubernetes cluster is running.  The master is running at:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://127.0.0.1&#34;&gt;http://127.0.0.1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;FLANNEL_NET
172.16.0.0/16
Using master 127.0.0.1
Wrote config for ubuntu to /home/root/.kube/config
&amp;hellip; calling validate-cluster&lt;/p&gt;

&lt;p&gt;Waiting for 1 ready nodes. 0 ready nodes, 0 registered. Retrying.
Found 1 nodes.
        NAME        LABELS                             STATUS
1       127.0.0.1   kubernetes.io/hostname=127.0.0.1   Ready
Validate output:
NAME                 STATUS    MESSAGE   ERROR
scheduler            Healthy   ok        nil
etcd-0               Healthy   {&amp;ldquo;action&amp;rdquo;:&amp;ldquo;get&amp;rdquo;,&amp;ldquo;node&amp;rdquo;:{&amp;ldquo;dir&amp;rdquo;:true,&amp;ldquo;nodes&amp;rdquo;:[{&amp;ldquo;key&amp;rdquo;:&amp;ldquo;/registry&amp;rdquo;,&amp;ldquo;dir&amp;rdquo;:true,&amp;ldquo;modifiedIndex&amp;rdquo;:3,&amp;ldquo;createdIndex&amp;rdquo;:3},{&amp;ldquo;key&amp;rdquo;:&amp;ldquo;/coreos.com&amp;rdquo;,&amp;ldquo;dir&amp;rdquo;:true,&amp;ldquo;modifiedIndex&amp;rdquo;:16,&amp;ldquo;createdIndex&amp;rdquo;:16}]}}
                     nil
controller-manager   Healthy   ok        nil
Cluster validation succeeded
Done, listing cluster services:&lt;/p&gt;

&lt;p&gt;Kubernetes master is running at &lt;a href=&#34;http://127.0.0.1:8080&#34;&gt;http://127.0.0.1:8080&lt;/a&gt;
```&lt;/p&gt;

&lt;p&gt;See Part 2 for setting up the server for starting up on reboot.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>django and docker</title>
      <link>http://blog.guthnur.net/django-and-docker/</link>
      <pubDate>Sun, 22 Nov 2015 19:03:28 -0800</pubDate>
      
      <guid>http://blog.guthnur.net/django-and-docker/</guid>
      <description>

&lt;p&gt;This guide shows you how to setup a Django Application and development environment using Docker and Postgres.&lt;/p&gt;

&lt;h4 id=&#34;1-install-the-docker-toolbox:872107b178d0c51c73a0d80068754fa1&#34;&gt;1. Install the Docker Toolbox&lt;/h4&gt;

&lt;p&gt;The first step is to install the &lt;a href=&#34;https://docs.docker.com/installation/&#34;&gt;docker toolbox&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;On this page, find your platform and run the installation. On a Mac, you&amp;rsquo;ll be installing Docker, Docker Compose, and Docker Machine. Docker Machine will use a Linux Virtual Machine to actually run Docker.&lt;/p&gt;

&lt;h4 id=&#34;2-docker-quickstart-terminal-mac:872107b178d0c51c73a0d80068754fa1&#34;&gt;2. Docker Quickstart Terminal (Mac)&lt;/h4&gt;

&lt;p&gt;If you&amp;rsquo;re using a Mac, you will want to start working with Docker by opening the Docker Quickstart Terminal. This will ensure that your environment is setup properly. Since Docker is actually running in a VM.&lt;/p&gt;

&lt;h4 id=&#34;3-get-familiar-with-docker:872107b178d0c51c73a0d80068754fa1&#34;&gt;3. Get familiar with Docker&lt;/h4&gt;

&lt;p&gt;For our Django app we are going to build a custom Django image. There is a lot to learn about Docker images in the future, so you should definitely read up on them when your ready.&lt;/p&gt;

&lt;p&gt;For this demo, you will want to create a directory to store all your files. I&amp;rsquo;ve created a directory called ~/build/django-docker. You can do this with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p ~/build/django-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and go to this directory&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd ~/build/django-docker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now create a file in this directory called Dockerfile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add the following to the Dockerfile:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM python:2.7
ENV PYTHONUNBUFFERED 1
RUN mkdir /code
WORKDIR /code
ADD requirements.txt /code/
RUN pip install -r requirements.txt
ADD . /code/
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-create-your-requirements-txt-file:872107b178d0c51c73a0d80068754fa1&#34;&gt;4. Create your requirements.txt file&lt;/h4&gt;

&lt;p&gt;The requirements.txt file contains the python modules necessary to run your application. In this case when need to install Django and psycopg2 (postgres + python). The Dockerfile we created in the previous setup will install these required modules.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;touch requirements.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And open this file to edit. Add the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;django
psycopg2
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;5-create-your-docker-compose-yml-file:872107b178d0c51c73a0d80068754fa1&#34;&gt;5. Create your docker-compose.yml file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;touch docker-compose.yml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And open this file to edit. Add the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;db:
  image: postgres
web:
  build: .
  command: python manage.py runserver 0.0.0.0:8000
  volumes:
    - .:/code
  ports:
    - &amp;quot;8000:8000&amp;quot;
  links:
    - db
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;6-create-your-django-project:872107b178d0c51c73a0d80068754fa1&#34;&gt;6. Create your Django project&lt;/h4&gt;

&lt;p&gt;You&amp;rsquo;ll need to use the docker-compose run command to start your django project. Of course, if you&amp;rsquo;ve already got a project started this setup can be skipped. You might still find this helpful to read through.&lt;/p&gt;

&lt;p&gt;In your docker-compose.yml file, we have specified the command we want to run as python manage.py runserver 0.0.0.0:8000. This is the command that will be run when we bring up our web container using docker-compose up. But before we can get to that point, we actually need a django project. To do this we will need to run a command against our web service using docker-compose run&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose run web django-admin.py startproject exampleproject .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You may already be familiar with djangos startproject command, but when using Docker we will have to run this command inside the of our container. Once you run this command you can run ls -l and take a look at the file that were created in your current directory. You will see that your project was created and manage.py was added, but both are owned by root. This is because the container runs as root. You&amp;rsquo;ll want to change the ownership by running sudo chown -R $USER:$USER .&lt;/p&gt;

&lt;h4 id=&#34;7-configure-django-to-connect-to-the-database:872107b178d0c51c73a0d80068754fa1&#34;&gt;7. Configure Django to connect to the Database&lt;/h4&gt;

&lt;p&gt;Django&amp;rsquo;s database settings are in the settings.py file located in your primary app directory &lt;code&gt;examplepoject/settings.py&lt;/code&gt; Go ahead and open this file to edit.&lt;/p&gt;

&lt;p&gt;Search for DATABASES and ensure the configuration looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DATABASE = {
  &#39;default&#39;: {
    &#39;ENGINE&#39;: &#39;django.db.backends.postgresql_psycopg2&#39;,
    &#39;NAME&#39;: &#39;postgres&#39;,
    &#39;USER&#39;: &#39;postgres&#39;,
    &#39;HOST&#39;: &#39;db&#39;,
    &#39;PORT&#39;: 5342
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice the hostname. If you look back at your docker-compose file, this is the name of the database service we&amp;rsquo;are creating. When we link the database container to the web container, we are able to access the container using the name of the service as the hostname.&lt;/p&gt;

&lt;h4 id=&#34;8-run-docker-compose-up:872107b178d0c51c73a0d80068754fa1&#34;&gt;8. Run docker-compose up&lt;/h4&gt;

&lt;p&gt;At this point we&amp;rsquo;re ready to take a look at our empty application. Run docker-compose up to start the django server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you&amp;rsquo;re on a Mac you&amp;rsquo;ll need to grab the ip of your Docker virtual machine by running:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-machine ip default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;otherwise you can use localhost. In my case the ip is 192.168.99.100. So open a browser and visit &lt;a href=&#34;http://192.168.99.100:8000&#34;&gt;http://192.168.99.100:8000&lt;/a&gt;. Again if you look at the docker-compose file under the ports directive we are forwarding port 8000 from our container to port 8000 on our machine running docker.&lt;/p&gt;

&lt;h4 id=&#34;9-add-data-persistence:872107b178d0c51c73a0d80068754fa1&#34;&gt;9. Add data persistence&lt;/h4&gt;

&lt;p&gt;For development, you may want to add a persistent data container. Whenever you start a new container from an image, you are starting completely fresh. That means when you start a new postgres container, it doesn&amp;rsquo;t start with any data. You&amp;rsquo;ll have to run migrations again, and you will have lost any data you my have added to some other container. This may seem odd at first, but in the end it&amp;rsquo;s essential to the portability of containers. So in theory, we can create a data only container that will be mounted onto our postgres container.&lt;/p&gt;

&lt;p&gt;To do this, lets first create an image called pg_data. To do this we will need to create another Dockerfile. I normally create a directory called docker to manage my docker-related files. So this is what I&amp;rsquo;l do, but you can put the file wherever you&amp;rsquo;d like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p docker/dockerfiles/pg_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then edit the file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd docker/dockerfiles/pg_data
vim Dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add the following to the Dockerfile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM busybox
VOLUME /var/lib/postgresql
CMD [&amp;quot;true&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now save the file and go ahead and create the image:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build -t pg_data .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, navigate back to the root directory of this app, and edit the docker-compose.yml file. Add the following to mount our data only container.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;web:
  build: .
  command: python manage.py runserver 0.0.0.0:8000
  volumes:
    - .:/code
  ports:
    - &amp;quot;8000:8000&amp;quot;
  links:
    - db
db:
  image: postgres
  volumes_from:
    - pg_data
pg_data:
  image: pg_data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll see we added a pg_data service and we&amp;rsquo;re mounting a data volume from pg_Data onto our db container. So now, as you develop and create data, as long as you mount this data only container to your future postgres containers you will have persistent data.&lt;/p&gt;

&lt;h4 id=&#34;10-running-tests:872107b178d0c51c73a0d80068754fa1&#34;&gt;10. Running tests&lt;/h4&gt;

&lt;p&gt;Running test is fairly straight forward. You can run a basic test using the docker-compose run command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose run web python manage.py test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But what if you want to automate the test? I was recently inspired to automate a test in my deployment script. So when running my deployment script, I would first spin up a docker container, run tests, and if the tests pass I can continue with the deployment. Otherwise, we stop and fix the issues.&lt;/p&gt;

&lt;p&gt;I create a test script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/bash
python manage.py test --noinput 2&amp;gt; /var/log/test.log 1&amp;gt; /dev/null

if [ $? -ne 0];then
  cat /var/log/test.log
  exit 1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And then in my deployment script I added the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-compose run --rm web ./bin/test.sh

if [ $? -ne 0 ];then
  echo &amp;quot;Tests did not pass! Fix them!&amp;quot;
  exit 1
fi
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &amp;ndash;rm flag removes the containers immediately after they stop.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>a start up story</title>
      <link>http://blog.guthnur.net/start-up-story/</link>
      <pubDate>Sun, 15 Nov 2015 14:22:57 -0800</pubDate>
      
      <guid>http://blog.guthnur.net/start-up-story/</guid>
      <description>

&lt;h3 id=&#34;creating-a-startup:c9c85e47c1600296732c38a16bbab580&#34;&gt;Creating a startup&lt;/h3&gt;

&lt;p&gt;So I have taken it upon myself to create a startup and see if I can&amp;rsquo;t get it actually used. So first thing you need is a great Idea that you believe in.
Then you need a great pitch no more then 30 seconds to get people excited. You need people you can get excited and keep them excited. These people will
become your Team and investors. Everyone you bring on or part of the startup needs to be as excited as you or more excited about the idea.&lt;/p&gt;

&lt;h3 id=&#34;step-number-two:c9c85e47c1600296732c38a16bbab580&#34;&gt;Step Number Two&lt;/h3&gt;

&lt;p&gt;The technology your going to use. This is the next important bit. You should really evaluate your past experiences. For example I use to work for a company
thats Ideas of scaling wasn&amp;rsquo;t true scaling, but just turn up more machines with out justification. At this step METRICS are going to be your life. You will
 want to make you everything measurable. Everything and I mean everything. You want metrics on how long it takes to install your base system, how long it
 takes to build docker containers. How much resources every single action takes. This allows you to scale effectively and to plan on how much time it will
 take you recover from a reddit front page. You will want to see how long for example it takes a payment to process in the foreground versus kicking it off
 in the back ground.&lt;/p&gt;

&lt;p&gt;Metrics should become your ZEN and you shouldn&amp;rsquo;t make a single business choice without metrics proving or disproving any trends or ideas. Then tie that to a
 dollar amount. Everything costs you money and If its going to take you 30 minutes to recover or spin up enough servers to handle the load from reddit or
 tech crunch and that is costing you $30.00/second then that 30 minutes really costs you $54,000 not to mention a bad user experience.&lt;/p&gt;

&lt;h3 id=&#34;user-experience:c9c85e47c1600296732c38a16bbab580&#34;&gt;User experience&lt;/h3&gt;

&lt;p&gt;This is the most important thing period. You could have the greatest full stack and deployment powers. If you don&amp;rsquo;t have the best user experience you will
 not have customers of user your product. If you don&amp;rsquo;t have customers or people wanting to use your product guess what you don&amp;rsquo;t have any money. You can also
 have the greatest customer experience and not have the functionality on the backend for the experience. People would rather have a great experience then a
 functional one. Make sure you design your product in mind for the market that your trying to hit. Example you would design something for the 18 to 35 crowd
 differently than for the 35 to 65 crowd. The old the customer the more they just want things to work versus the younger crowd that understands things break.&lt;/p&gt;

&lt;p&gt;Stay Tuned for more Startup Tips.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>letsencrypt yay</title>
      <link>http://blog.guthnur.net/letsencrypt-yay/</link>
      <pubDate>Sun, 15 Nov 2015 13:10:41 -0800</pubDate>
      
      <guid>http://blog.guthnur.net/letsencrypt-yay/</guid>
      <description>

&lt;h3 id=&#34;letsencrypt:ae187b386f0c86f5be8053e8af7b56b5&#34;&gt;letsencrypt&lt;/h3&gt;

&lt;p&gt;This is a amazing product that is opensource. I recently decided that this was going to be the way I get my ssl certificates for everything I do. I was
lucky to get into the beta invitation only. It works great. Every 90 days you have regen your certificates but thats not a big deal because they give you
tools to do it.&lt;/p&gt;

&lt;h4 id=&#34;setup:ae187b386f0c86f5be8053e8af7b56b5&#34;&gt;Setup&lt;/h4&gt;

&lt;p&gt;So you get this going to your going to need to check out their repo.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/letsencrypt/letsencrypt
  cd letsencrypt
  ./letsencrypt-auto --server \
      https://acme-v01.api.letsencrypt.org/directory --help
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next after you get your domains submitted for the beta and registered you will want to do the following commands. Heres how for apache:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./letsencrypt-auto --apache --server https://acme-v01.api.letsencrypt.org/directory --agree-dev-preview
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For standalone Apache you would do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./letsencrypt-auto certonly -a standalone \
  -d example.com -d www.example.com \
  --server https://acme-v01.api.letsencrypt.org/directory --agree-dev-preview
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If your like me and use nginx for your server you will need to do the following to get it working:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./letsencrypt-auto certonly -a manual -d www.stbtx.com -d example.com -d blog.example.com --webroot-path /var/www/html --server https://acme-v01.api.letsencrypt.org/directory --agree-dev-preview
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you will need to do the following openssl command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl dhparam -out dhparam.pem 4096
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then in the Nginx server block add the following SSL configuration:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# SSL configuration
	listen 443 ssl default_server;
	listen [::]:443 ssl default_server;
	ssl_certificate /etc/letsencrypt/live/{domain}/fullchain.pem;
    	ssl_certificate_key /etc/letsencrypt/live/{domain}/privkey.pem;
    	ssl_session_timeout 1d;
    	ssl_session_cache shared:SSL:10m;
    	ssl_session_tickets off;
	    # openssl dhparam -out dhparam.pem 2048
    	ssl_dhparam /etc/nginx/dhparam.pem;

    	ssl_protocols TLSv1.1 TLSv1.2;
    	ssl_ciphers &#39;ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK&#39;;
    	ssl_prefer_server_ciphers on;

    	add_header Strict-Transport-Security max-age=15768000;

    	ssl_stapling on;
    	ssl_stapling_verify on;

    	## verify chain of trust of OCSP response using Root CA and Intermediate certs
    	#ssl_trusted_certificate /path/to/root_CA_cert_plus_intermediates; ## Addition CA certs
    	ssl_trusted_certificate /etc/letsencrypt/live/{domain}/chain.pem;
    	resolver 8.8.8.8 8.8.4.4 valid=86400;
	resolver_timeout 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Restart your nginx server and you will be golden. This will support HSTS, SPDY and SSL.&lt;/p&gt;

&lt;p&gt;There you have deployed letencrypt certificates to your server woot! :) Great job!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>dStar a Great Time!</title>
      <link>http://blog.guthnur.net/dstar-great-time/</link>
      <pubDate>Mon, 21 Sep 2015 12:29:04 -0700</pubDate>
      
      <guid>http://blog.guthnur.net/dstar-great-time/</guid>
      <description>

&lt;p&gt;So I have finally taken the jump in to d*Star. I picked up a Icom ID-51A Plus from the guys over at &lt;a href=&#34;https://www.hamradio.com&#34;&gt;Ham Radio Outlet&lt;/a&gt;. Digital Modes
have interested me for a while. Since I live more than 30 miles from the nearest d*Star repeater, I picked up a DVAP 2meter Dongle. So my d*Star setup is a raspberry
pi b+ v2 + DVAP 2m and my Icom ID-51A Plus radio. So I&amp;rsquo;ll explain how to get this setup. It took a lot of digging around the internet to get a complete set together.&lt;/p&gt;

&lt;h3 id=&#34;configure-icom-id-51a-plus-to-use-dstar:7ab37d811a3fb6122eb1daaec1b9fa57&#34;&gt;Configure Icom ID-51A Plus to use Dstar&lt;/h3&gt;

&lt;p&gt;So turn on your Icom ID-51A Plus. Press the menu button and nagivate to My Station and press the &amp;ldquo;blue&amp;rdquo; ok button in the middle of the dpad. Then Ok on My Call Sign. Then the first one should be selected by default. Press the Quick button and this will pop up with a menu of Edit and Clear. Click ok on edit. Now turn the little nob to navigate thought the alpha numeric options. Once your have your call sign in there click ok twice. This should take you back to My station list. Now aarow down to TXT Message. Select option 1. Press the quick button again. Put in your Name. Then ok twice again. Now we need put in a repeater for our dvap. Press and hold the DR button (Aka the Down Button.) Then highlight the From then press the ok button. Then ok on Repeater List. Scroll down to 20: Simplex. Next Press the Quick button and scroll down to Add and press the ok button. Set the Type: DV Repeater, scroll to Name, Use the small nob like you did to set your call sign, to give it the name of DVAP. Then scroll down to Use(From): Test this to yes. Next go to frequency and set it to a frequency that is available in your area. Remeber this as you will need this when we setup the PI + Dvap. Scroll down to Add to write and click ok. Now your DVAP should be in the From field. Next scroll to TO and Tell it ok and choose reflector. Then Ok on link to reflector. Then ok on Direct Input. Turn the small nob to a reflector number of your choosing. REF001C is busy reflector and REF050C is a busy one in the northeast of the US. Then click ok. Now our radio is ready. Next is the PI+DVAP setup.&lt;/p&gt;

&lt;h3 id=&#34;setup-raspberry-pi-and-dvap:7ab37d811a3fb6122eb1daaec1b9fa57&#34;&gt;Setup Raspberry Pi and DVAP&lt;/h3&gt;

&lt;p&gt;So you will want to ssh to your raspberry pi as the pi user. I would recommend that you use the standard raspbian jessie image. You can get this at
&lt;a href=&#34;https://www.raspberrypi.org/downloads/raspbian/&#34;&gt;Downloads @ Raspberrypi.org&lt;/a&gt;. You can follow their documentation on getting this on the SD card. Next you will
want to do &lt;code&gt;apt-get update &amp;amp;&amp;amp; apt-get upgrade&lt;/code&gt; to make sure you have everything is current. Next we need to install some supporting packages:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install x11vnc vim libwxgtk2.8-0:armhf libwxgtk2.8-dev libwx-gtk2 libwx-gtk2u libwxbase2.8-0:armhf libwxbase2.8-dev libportaudio2:armhf libportaudiocpp0:armhf portaudio19-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we will need to install klxupdate. This is going to handle installing all the correct packages needed for the repeater and gateway. So will run the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; wget http://www.westerndstar.co.uk/KLXstuff/klxupdate; sudo install -g bin -o root -m 0775 ./klxupdate &amp;quot;/usr/local/bin&amp;quot; ; sudo rm ./klxupdate
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we will install the repeater application using &lt;code&gt;klxupdate repeater&lt;/code&gt;. Select 9 to install the latest version and answer Y to the question. Repeater is fairly quick to install. Next will install the gateway application &lt;code&gt;klxupdate gateway&lt;/code&gt;. Select 9 to install the latest version and answer Y to the question. Gateway takes a few minutes to install. Next we need to make some desktop icons to make it easier to access the applications. So we are going to change Directory to &lt;code&gt;cd /home/pi/Desktop&lt;/code&gt;. So we are going to use vim to create these files. So run &lt;code&gt;vim gateway.desktop&lt;/code&gt; and then paste&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Name=ircDDBGateway
Comment=Application for running ircDDBgateway
Exec=sudo ircddbgateway -gui
Icon=/usr/share/pixmaps/openbox.xpm
Terminal=false
Type=Application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then hit esc then &lt;code&gt;:wq&lt;/code&gt; this will write the file out and quit vim. Next we are going to create gateway_config.desktop using vim &lt;code&gt;vim gateway_config.desktop&lt;/code&gt;. We are going to paste the following that file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Name=Gateway Config
Comment=Application for configuring ircDDBGateway
Exec=sudo ircddbgatewayconfig
Icon=/usr/share/pixmaps/obconf.xpm
Terminal=false
Type=Application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then hit esc then &lt;code&gt;:wq&lt;/code&gt; this will write the file out and quit vim.
Next is dstar.desktop, we need to make also make this in vim using that same steps as before. Then we are going to paste the following in that file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Name=D-Star Repeater
Comment=Application for running D-Star
Exec=sudo dstarrepeater -gui
Icon=/usr/share/pixmaps/openbox.xpm
Terminal=false
Type=Application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we are going to create dstar_config.desktop using the same process as the last 3 files before. Then we are going to paste the following into the file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Name=D-Star Config
Comment=Application for configuring D-Star Repeater
Exec=sudo dstarrepeaterconfig
Icon=/usr/share/pixmaps/obconf.xpm
Type=Application
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we are going to setup x11vnc, so we can remote into the pi and use the gui tools to configure the tools. While we are still ssh&amp;rsquo;d into the pi. We are going to setup x11vnc password. We are going to run &lt;code&gt;x11vnc -storepasswd&lt;/code&gt; next we need to make it so vnc starts with the pi. We are going to change directories to &lt;code&gt;cd /etc/init.d/&lt;/code&gt; then we are going to use wget again to download a init script. &lt;code&gt;wget http://www.vk3erw.com/download/vncboot&lt;/code&gt; Next we need to make it executable using the following command &lt;code&gt;chmod 775 /etc/init.d/vncboot&lt;/code&gt; now that have it executable. We need to update the system defaults, using &lt;code&gt;update-rc.d vncboot defaults&lt;/code&gt;. Next we need to update &lt;code&gt;/boot/config.txt&lt;/code&gt;. We need to do this becuase without a HDMI monitor connected you may find the VNC session results in a very small screen. This is due to the default graphics mode on boot. You can force a larger screen by modifying /boot/config.txt:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo vim /boot/config.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Uncomment and modifying the following lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hdmi_force_hotplug=1
hdmi_group=2
hdmi_mode=58
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we are going to reboot the pi. &lt;code&gt;sudo reboot&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&#34;configure-applications:7ab37d811a3fb6122eb1daaec1b9fa57&#34;&gt;Configure applications&lt;/h4&gt;

&lt;p&gt;First we are going to configure the gateway. So VNC to the the pi using a vnc client like chicken of vnc(on mac os x). We are going to double click on gateway_config. Its going to take a bit to getting up on the screen. Once up on the screen we are going to make some changes, to what we see on the screen. We are going to set the drop down box to &lt;code&gt;hotspot&lt;/code&gt;. Next we are going to set the callsign to our callsign. Next boxes we are going to touch are the QTH to your location. Next we are going to the Reapter 1 tab. We are going to set the Band to C for 2m or B for 70cm. The type needs to be set to Homebrew. If you want to automatically link to a reflector, then set the Reflector to the reflector you want and the band. You want to set Startup to yes in this case. On the next Repeater make sure that Freq, offset, Range, AGL, Lat and Long are all set to 0. Next we are going to click the right arrow until we are get to ircDDB tab. Set ircDDB to Enabled and hostname to freestar-irc-cluster.v3lsr.ca, put your callsign in for the username. Since this server doesn&amp;rsquo;t need you to register your callsign. Next click the right aarow again to D-PRS and set it to enable. If the hostname is blank put in rotate.aprs2.net and port 14580. Next click the right arrow again for DExtra, set it to Enabled if you wish to use DExtra. Click the right aarow to go to D-Plus and set this to enable and set Login to your callsign. Click the Right Arrow again to bring you to the DCS and CCS tab. Set DCS and CCS to Enabled. Next click the right arrow until you get to the end of the tabs. Set info command, echo command, gui log, D-Rats, DTMF Control all to Enabled. Next go to File -&amp;gt; Save. Now close this window.&lt;/p&gt;

&lt;p&gt;Next double click on D-Star Config on the Desktop. Once the window opens up. We are going to set callsign and gateway to our callsign. Next to the callsign field is a drop which is the bands and in my case since a I have 2meter DVAP I have this set to C. Mode you want to set to Simplex. Also want to make Restrict, RTP1 Validation to Off. DTMF Blanking and Error Reply set to ON. Click on beacon to every 10 minutes, Put your callsign plus the band in the message. Enable the Voice and set the langauge of your country. Click the right aarow to Control 1. We are going enable Enabled. Set RPT1 Callsign to RPTRCTLC and RPT2 Callsign to K1MOS&lt;space&gt;G. Now Click on the Modem tab and set the type to DVAP. Now click Configure&amp;hellip; button. Set port to /dev/ttyUSB0 or the port that the DVAP is using. Set the Band to the band for your dvap. Next we need to pick a frequency that isn&amp;rsquo;t being used near you. So check your repeater lists, next the with the frequency scanner of your radio. Set the power to 10 dBm and squelch to -100dBm. Click on ok. Then file -&amp;gt; save.&lt;/p&gt;

&lt;p&gt;Next click on ircDDBGateway and wait for it to connect. Once it says ircDDB Connected and Reapter 1 is linked. Then double click on D-Star Repeater. You should see Status RX State: Listening. To make sure its connected.&lt;/p&gt;

&lt;p&gt;To Test this Turn on your radio to the Freq that you have chosen. Key the radio and you should see the traffic from your Dstar Radio in this window.&lt;/p&gt;

&lt;p&gt;Next now that we have the radio configured we want to setup the pi to automatically start these applications.&lt;/p&gt;

&lt;p&gt;Open a Terminal applicaiton or ssh to the pi. Execute the following commands.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo su -
cd /home/pi/.config/autostart
vim start_gateway.desktop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Paste the following in there:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Type=Application
Exec=sudo ircddbgateway -gui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Save this with the &lt;code&gt;:wq&lt;/code&gt;. Next we are going to create another file called &lt;code&gt;start_repeater.desktop&lt;/code&gt;. Paste the following into the file and save it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Desktop Entry]
Type=Application
Exec=sudo dstarrepeater -gui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the Hotspot/Repeater will start automatically.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>With Change Comes Adventure</title>
      <link>http://blog.guthnur.net/with-change-comes-adventure/</link>
      <pubDate>Fri, 18 Sep 2015 12:26:38 -0400</pubDate>
      
      <guid>http://blog.guthnur.net/with-change-comes-adventure/</guid>
      <description>

&lt;p&gt;The title says it all. There is has been a great change in my life. I have left the company I have been at for the past approx 7 years.
I have worked with some great people, learned a lot. I have also learned what it means to make something scalable. I have learned a lot of
what not to do. I&amp;rsquo;m looking forward to moving into more of a System Engineering role where I can focus on scaling application and cloud designed.&lt;/p&gt;

&lt;p&gt;I have left Symplicity Corporation. I have made a lateral move to CenturyLink Cloud as a Senior System Engineer. In my new position I will still be working
with clients and infrastructures. I will get the ability to get behind a application platform that scales to 57 datacenter and 10,000 of thousands of clients.
I will be able to move into DevOps or Automation in the future.&lt;/p&gt;

&lt;h3 id=&#34;reasons:1bcd761b05b9be29a4bbab0d39dbbfe0&#34;&gt;Reasons&lt;/h3&gt;

&lt;p&gt;I could list a million reasons why I have left Symplicity. It all comes down to the events for the past couple of years. Starting with the CEO and CTO getting charged with computer crimes. Human Resources promising career paths over and over and never delivering. No support for Professional development. Massive Turn over rates across the board. Lack of quality hires and hoping that craigslist is going to give rockstar devops and system engineers. Fear of growth and change. People being leaders that try their best only to fall short of being great leaders. Lack of a CTO and CIO to drive developers and sysadmins to greatness is really hurting the company.&lt;/p&gt;

&lt;h3 id=&#34;why-centurylink:1bcd761b05b9be29a4bbab0d39dbbfe0&#34;&gt;Why CenturyLink&lt;/h3&gt;

&lt;p&gt;Well they sought me out and their processes I have been greatly impressed with. They have a definitive goal and markets they want to get to. Their perks are great.
Professional Development, Health Insurance and Pay is amazing. There interview process is designed to filtered out a lot of crap applicants. It starts off by two phone technical interviews and then Team Manager phones you. Then you get flown to Seattle for a interview Loop that is 5 people, one person from the team, 2 other employees that you might interact with. Then the VP of the division talks with you and then Team Manager talks with you again. You only move on in the loop if the last person to interview likes you and feels that you fit in. There Customers are number 1 in thier book and there employees are number 1 also. They are building a culture that they are very very picky about who can join it and help build it.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m looking forward to where this career path is going to take me. Right now its very very promising from Century Link Cloud.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Containers are not VMs</title>
      <link>http://blog.guthnur.net/containers-are-not-vms/</link>
      <pubDate>Sat, 18 Jul 2015 23:53:49 -0400</pubDate>
      
      <guid>http://blog.guthnur.net/containers-are-not-vms/</guid>
      <description>

&lt;p&gt;So lately I have been digging deeper and deeper into containers and there
usefulness. It seems that a lot of people blur the line between VM&amp;rsquo;s and
Containers. I think its important that we define the two here before we get to
invested in this article.&lt;/p&gt;

&lt;h5 id=&#34;vm-concepts:f21460bb8361ebe9d0dfc1e78d4a74b8&#34;&gt;VM Concepts&lt;/h5&gt;

&lt;p&gt;A VM per its name is a Virtual Machine, so this by default is Read/Write
enabled. Where your changes aren&amp;rsquo;t lost in reboots or host shutdowns. This is
great for things where your not using source control. And your machine isn&amp;rsquo;t
defined as Code!.&lt;/p&gt;

&lt;h5 id=&#34;lxc-containers:f21460bb8361ebe9d0dfc1e78d4a74b8&#34;&gt;LXC Containers&lt;/h5&gt;

&lt;p&gt;Now lxc containers are read/write or even read only containers. This have the
same issue as VM&amp;rsquo;s and that is they arent defined by code. They have act like
VM&amp;rsquo;s or act in the ideaism&amp;rsquo;s of Docker containers if you wish. This dont have
a hypervisor, cgroups can be a nightmare to get working depending on our OS
they my or not work.&lt;/p&gt;

&lt;h5 id=&#34;docker-containers:f21460bb8361ebe9d0dfc1e78d4a74b8&#34;&gt;Docker Containers&lt;/h5&gt;

&lt;p&gt;Now Docker containers are defined as Code, but they are read only. So you can&amp;rsquo;t
use them as a vm and except your changes to stick unless you define it in the
code that makes the container. These typically only host one service, or one
task. Such as a Web Server or a Database server. Their cgroups work out of the
box.&lt;/p&gt;

&lt;h5 id=&#34;container-concepts:f21460bb8361ebe9d0dfc1e78d4a74b8&#34;&gt;Container Concepts&lt;/h5&gt;

&lt;p&gt;So the ideaism behind containers is this you have a service say nginx and your
going to host your website. 99% of the time your not going to need to increase
the number of nginx servers but the services that run php, ruby,etc. So you
would a nginx docker container, a php-fpm container set and haproxy. Your nginx
container would point to the HAProxy container which in turn points to the
php-fpm containers that you would scale based on demand. This is called one
service or one task containerism.&lt;/p&gt;

&lt;p&gt;So now that we have that cleared up. At work we are making the move to
containers and really considering docker over lxc. We have a lot of old school
thought of we need to make a quick fix just ssh to the containers and make the
fix. This is all good as long as you make sure the change is done at the
container code level before its forgotten. So that the next build of the
container has those changes. Moving to Infrastructure as Code from
a Infrastructure with 500 physical machines is a hard concept for a lot of
people to get behind. It requires a whole different train of thought. You have
to forget the idea of oh I can just ssh to there and do what I need. This is
called system drift. Your system configuration management tool should be the
only thing making changes. This is what I call Infrastructure as Pseudo Code.&lt;/p&gt;

&lt;p&gt;So how do we avoid drift in machines, or never having a machine at its
originally state ? Well this is where containers come in to play. You have the
host machine that is completely bare nothing more than what it needs to do its
job configured. Only services that should be installed are sshd, iscsi for
storage and nfs also for storage. Along with your container service of choice.
You only connect to the host when you want to get a container setup and
running.&lt;/p&gt;

&lt;p&gt;So you probably wondering what about a development environment. Local
development is how it should be done. Your developers should be able to have
access to resources to stand up a small production environment on their
machines. This eliminates the need to have a VM in production for developers to
work from. Since our Infrastructure is code now, the developer can just do
something simple like using a docker compose file to stand up a web, cache,
search and db all in a few minutes.&lt;/p&gt;

&lt;p&gt;This is a new way of thinking and it takes a lot of time to get people to see
that this style is how the industry is moving and to understand it. This is
a change that will not happen over night. If you grab some of your senior
developers and show them the process and how they can finally have a replica
environment that our clients have, this is priceless to them. Now they can
truly debug and aren&amp;rsquo;t tied to a vpn connection or a local network connection.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Auto Deployment using PHP and rabbitmq</title>
      <link>http://blog.guthnur.net/autodeployment-using-rabbitmq/</link>
      <pubDate>Mon, 13 Jul 2015 17:06:44 -0400</pubDate>
      
      <guid>http://blog.guthnur.net/autodeployment-using-rabbitmq/</guid>
      <description>&lt;p&gt;So for work for the past 3 weeks we took part of the 18F BPA contest for the US Government. I was tasked with building a docker setup that when &lt;a href=&#34;http://codeship.com&#34;&gt;codeship&lt;/a&gt; completed testing and building that it would automatically updated containers local code.
So I did this with a rabbitmq server using exchange queues. So the way this worked is this codeship would build the code, run all the test, push the update to a production branch. The way codeships webhook system works is this, it hits the end point every step. So this means we have
to listen for a status of success in order to make our nodes update. The webhook end in codeship points to a url for the site. Which checks the API key for the arbeider end point, codeship project id and for the message. This was a quick and dirty way to do it with out getting super complex.
Once the security stuff passes then we pop a json object in the rabbitmq exchange. The object looks like this&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;worker-api&amp;quot;:&amp;quot;lknas0d9ni1ipnd0icqnd1&amp;quot;,
  &amp;quot;git-command&amp;quot;:&amp;quot;update&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see in this object we pass along the worker api key. Every node will check this key, if it matches whats on their end then they will execute the git-command. In the case of our project we just run a update.sh script on the docker container, that checks the code out and makes sure the branch is correct.
I know your saying well your sending that in plain text. Yes I&amp;rsquo;m aware, if I was actually doing this in a production environment, that object would have been SHA-256 encrypted and the rabbitmq exchange would have encrypted also. Since this was just a proof of concept we choose to do it quickly. As we originally only had
one week to do this in.&lt;/p&gt;

&lt;p&gt;The flow of the application is this:
&lt;img src=&#34;http://blog.guthnur.net/images/workers-diagram.png&#34; alt=&#34;Image of the Workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see its extremely simple. It can be extended to do a lot more, such as sending signals to services to all nodes, or individual nodes. I&amp;rsquo;m hoping in my next revision that I will be able to get moving these to classes instead of random structured functions. Please contribute back to it and feel free to use it as a base for what you need in your environment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>new blog</title>
      <link>http://blog.guthnur.net/new-site/</link>
      <pubDate>Mon, 13 Jul 2015 15:11:04 -0400</pubDate>
      
      <guid>http://blog.guthnur.net/new-site/</guid>
      <description>

&lt;h3 id=&#34;finally-backup:874d006584b53f2a1070783574da19bd&#34;&gt;Finally Backup&lt;/h3&gt;

&lt;p&gt;So I have decided its time for a new site and blog. I have been playing with
this idea for a while. I have been really busy at work and in my personal life.
I originally started a blog back in 2004 and now here we are in 2015. With more
blog options then ever before.&lt;/p&gt;

&lt;h4 id=&#34;engine-choice:874d006584b53f2a1070783574da19bd&#34;&gt;Engine Choice&lt;/h4&gt;

&lt;p&gt;So when I picked my blog engine I knew I never wanted to have a database
server. I wanted the ability to throw this up on any thing that can serve html
statically. Theres a TON of static site generators all over the place. There
are written in various languages. I choose hugo written in GOLANG because one
I wanted to learn GOLANG and two its extremely well used based off my research
on github.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Me &amp; Contact Info</title>
      <link>http://blog.guthnur.net/about/</link>
      <pubDate>Wed, 01 Jan 2014 20:41:11 -0600</pubDate>
      
      <guid>http://blog.guthnur.net/about/</guid>
      <description>

&lt;p&gt;Richard Genthner is a System Administrator, FireFighter, EMT living in
Waldoboro Maine. In my spare time you can find me giving my time to my family
and community.&lt;/p&gt;

&lt;p&gt;This website is meant primarily as a way to get my name out and distrubute my
resume, but it also will service as a platform for me to write about my
experiences at work and in my personal life.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m Available for hire.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;other-links:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;Other Links&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/moos3&#34;&gt;Github&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;contact-me:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;Contact Me&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Richard Genthner&lt;/strong&gt;
545 Union Rd&lt;br /&gt;
Waldoboro, Maine USA 04572&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;guthnur.net&#34;&gt;guthnur.net&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;mailto:richard@guthnur.net&#34;&gt;richard@guthnur.net&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.guthnur.net/media/gpgKey/moosePubKey.asc&#34;&gt;GPG Key&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>